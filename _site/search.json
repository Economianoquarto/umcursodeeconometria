[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Um Curso de Econometria",
    "section": "",
    "text": "Aulas\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAulas\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Economia no Quarto",
    "section": "",
    "text": "Caio Lopes é professor da Universidade Federal do Piauí desde 2018\n\n\nDoutorado em Desenvolvimento Econômico. Universidade Federal do Paraná, UFPR, Brasil | 2016 - 2020\nMestrado em Economia. Universidade de São Paulo, USP-RP, Brasil | 2013 - 2015\nGraduação em Ciências Econômicas. Universidade de São Paulo, USP, Brasil | 2009 - 2012"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Modelo Clássico de Regressão MCRL",
    "section": "",
    "text": "Hipóteses do Modelo Clássico de Regressão Linear Múltipla (MCRLM)\nEquação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html",
    "href": "posts/Modelo de Equações Estruturais/index.html",
    "title": "Modelo de Equações Estruturais",
    "section": "",
    "text": "Este material aborda os Modelos de Equações Estruturais (MEE) ou Structural Equation Model (SEM)"
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#variáveis-observadas-vs.-variáveis-latentes",
    "href": "posts/Modelo de Equações Estruturais/index.html#variáveis-observadas-vs.-variáveis-latentes",
    "title": "Modelo de Equações Estruturais",
    "section": "Variáveis Observadas vs. Variáveis Latentes",
    "text": "Variáveis Observadas vs. Variáveis Latentes\nNo SEM, distinguimos entre dois tipos principais de variáveis : Variáveis Observadas: São variáveis que existem diretamente nos dados e podem ser medidas sem erro.\nVariáveis Latentes: São variáveis construídas e que não existem diretamente nos dados; são hipóteses teóricas. Elas são mensuradas indiretamente através de suas variáveis observadas (indicadores) por meio de análise fatorial confirmatória\nAlém disso, as variáveis podem ser classificadas como:\nVariável Exógena: Uma variável independente que explica uma variável endógena. Pode ser observada (representada por ‘x’) ou latente (representada por ‘\\(\\xi\\)’).\nVariável Endógena: Uma variável dependente que é explicada por outras variáveis no modelo. Pode ser observada (representada por ‘y’) ou latente (representada por ‘\\(\\eta\\)’). Em modelos de análise de trajetória, uma variável endógena pode predizer outra variável endógena."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#diagramas-de-trajetória",
    "href": "posts/Modelo de Equações Estruturais/index.html#diagramas-de-trajetória",
    "title": "Modelo de Equações Estruturais",
    "section": "Diagramas de Trajetória",
    "text": "Diagramas de Trajetória\nOs diagramas de trajetória são representações visuais essenciais dos modelos SEM, facilitando a compreensão das relações complexas que podem ser difíceis de visualizar apenas com equações matriciais [11, 12, 30].\nOs símbolos utilizados nos diagramas são padronizados [11, 30]: * Círculos: Representam variáveis latentes (fatores ou construtos). * Quadrados: Representam variáveis observadas (indicadores ou itens). * Triângulos: Representam interceptos ou médias (geralmente não explicitados por padrão no lavaan a menos que solicitados) [11, 31]. * Setas únicas (de uma via): Indicam caminhos de regressão ou relações causais diretas (ex: uma variável predizendo outra) [11, 30, 32]. * Setas duplas (de duas vias): Indicam variâncias (se a seta aponta para a própria variável, formando um loop) ou covariâncias (se a seta conecta duas variáveis) [11, 30, 32].\nExemplo de leitura de um diagrama [11, 33]: * Uma seta de um círculo para um quadrado indica que uma variável latente (fator) prediz uma variável observada (indicador), o que é parte de um modelo de mensuração. * Uma seta dupla em um círculo ou quadrado representa a variância daquela variável (latente ou observada). * Uma seta dupla entre dois círculos ou dois quadrados indica a covariância entre essas duas variáveis."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#modelo-de-mensuração-e-modelo-estrutural",
    "href": "posts/Modelo de Equações Estruturais/index.html#modelo-de-mensuração-e-modelo-estrutural",
    "title": "Modelo de Equações Estruturais",
    "section": "Modelo de Mensuração e Modelo Estrutural",
    "text": "Modelo de Mensuração e Modelo Estrutural\nO SEM é singular por abranger tanto modelos de medida ou de mensuração quanto modelos estruturais:\n\nModelo de Mensuração: É a parte do SEM que liga variáveis observadas a variáveis latentes. Sua função é mensurar construtos latentes a partir de variáveis observadas . Envolve a Análise Fatorial Confirmatória (AFC).\n\nNeste modelo, as variáveis observadas que medem um fator são chamadas de indicadores.\nUm fator (variável latente) é definido por seus indicadores. A relação entre um indicador e um fator é chamada de carga fatorial (loading).\n\nModelo Estrutural: A parte do SEM que especifica as relações causais entre variáveis, sejam elas observadas ou latentes. Pode envolver relações de variáveis exógenas para endógenas, e até mesmo de variáveis endógenas para outras variáveis endógenas.\n\nO tipo mais abrangente de modelo estrutural, a regressão estrutural, lida com as relações entre variáveis latentes.\nAs relações são definidas por coeficientes de regressão: \\(\\Gamma\\) (Gamma) para relações de variáveis exógenas para endógenas, e \\(B\\) (Beta) para relações de variáveis endógenas para outras variáveis endógenas."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#estimação-máxima-verossimilhança-e-teste-de-modelos-goodness-of-fit",
    "href": "posts/Modelo de Equações Estruturais/index.html#estimação-máxima-verossimilhança-e-teste-de-modelos-goodness-of-fit",
    "title": "Modelo de Equações Estruturais",
    "section": "Estimação (Máxima Verossimilhança) e Teste de Modelos (Goodness-of-Fit)",
    "text": "Estimação (Máxima Verossimilhança) e Teste de Modelos (Goodness-of-Fit)\n\nEstimação\nNo SEM, os modelos são tipicamente estimados utilizando o método de Máxima Verossimilhança (ML). A ML busca os parâmetros que tornam a amostra observada mais provável, ou seja, maximiza a função de verossimilhança para determinar os parâmetros que têm maior probabilidade de produzir os dados observados. É importante notar que, embora os coeficientes de regressão de uma estimação por Mínimos Quadrados Ordinários (MQO) sejam equivalentes aos da Máxima Verossimilhança, as variâncias residuais podem diferir ligeiramente devido às diferentes bases de cálculo (divisão por \\(N-k\\) para MQO e \\(N\\) para ML).\nO componente mais essencial de um modelo de equações estruturais é a matriz de covariância. O objetivo do SEM é reproduzir a matriz de covariância da população (\\(\\Sigma\\)) usando os parâmetros que o modelo hipotetiza (\\(\\Sigma(\\theta)\\)), conhecida como matriz de covariância implicada pelo modelo. Se o modelo se ajusta perfeitamente, então \\(\\Sigma = \\Sigma(\\theta)\\).\n\n\nIdentificação do Modelo\nA identificação de um modelo SEM é crucial para garantir que os parâmetros possam ser estimados de forma única. Modelos podem ser classificados como:\n\nSub-identificados: O número de valores conhecidos é menor que o número de parâmetros livres (\\(df < 0\\)). Não há solução única para a estimação.\nJustamente Identificados (ou Saturados): O número de valores conhecidos é igual ao número de parâmetros livres (\\(df = 0\\)). O modelo se ajusta perfeitamente aos dados.Modelos de regressão linear simples e múltipla são exemplos de modelos saturados .\nSobre-identificados: O número de valores conhecidos é maior que o número de parâmetros livres (\\(df > 0\\)). O modelo não se ajusta perfeitamente, mas permite a avaliação da qualidade do ajuste. Modelos sobre-identificados são considerados “bons”, pois permitem avaliar o ajuste do modelo .\n\nPara modelos de análise fatorial (medida), a identificação do fator é particularmente importante, pois variáveis latentes não são observadas diretamente. Para um modelo com três ou mais indicadores, existem duas abordagens principais para identificação:\n\n\nMétodo do Marcador (Marker Method): Fixa a primeira carga fatorial de cada fator em 1. Este é o método padrão no lavaan .\n\n\nMétodo de Padronização da Variância (Variance Standardization Method): Fixa a variância de cada fator em 1, mas estima livremente todas as cargas fatoriais . Este método é considerado mais padronizado e útil para interpretação.\n\n\n\n\nEstatísticas de Qualidade do Ajuste (Model Fit Statistics)\nAs estatísticas de qualidade do ajuste avaliam o quão bem o modelo populacional se ajusta aos dados observados. A hipótese nula no SEM é que a matriz de covariância implicada pelo modelo (\\(\\Sigma(\\theta)\\)) é igual à matriz de covariância da população (\\(\\Sigma\\)) (\\(H_0: \\Sigma(\\theta)=\\Sigma\\)). Rejeitar esta hipótese é geralmente indesejável no SEM, pois significaria que o modelo proposto não se ajusta bem aos dados.\n\nCovariância Residual: A diferença entre a matriz de covariância amostral (\\(S\\)) e a matriz de covariância implicada pelo modelo (\\(\\Sigma(\\hat{\\theta})\\)), ou seja, \\(S - \\Sigma(\\hat{\\theta})\\). Valores próximos de zero indicam um bom ajuste.\nTeste Chi-quadrado do Modelo (\\(\\chi^2\\)): É a estatística de teste principal que mede a discrepância entre a matriz de covariância observada e a matriz de covariância implicada pelo modelo [28, 66, 68, 69].\n\nUm valor de chi-quadrado maior indica uma maior diferença (pior ajuste) entre as matrizes e, consequentemente, uma maior probabilidade de rejeitar a hipótese nula [68, 70].\nSensibilidade ao tamanho da amostra: O teste chi-quadrado é altamente sensível a amostras grandes. Em amostras grandes, é comum que o teste seja estatisticamente significativo mesmo para modelos com bom ajuste prático . Por isso, o chi-quadrado sozinho não deve ser o único critério de avaliação de ajuste.\n\nModelo de Linha de Base (Baseline Model): Considerado o modelo de “pior ajuste”. Ele assume que não há covariância entre quaisquer variáveis, estimando apenas as variâncias de cada uma. Serve como ponto de comparação para os índices de ajuste incrementais.\nÍndices de Ajuste Aproximados: Desenvolvidos para complementar o teste chi-quadrado, atenuando sua sensibilidade ao tamanho da amostra.\n\nÍndices de Ajuste Incrementais (ou Relativos): Avaliam a melhoria do ajuste do modelo do usuário em relação ao modelo de linha de base.\nCFI (Comparative Fit Index): Varia de 0 a 1. Valores maiores que 0.90 (conservadoramente 0.95) indicam bom ajuste. Quanto mais próximo de 1, melhor o ajuste.\nTLI (Tucker-Lewis Index): Também varia de 0 a 1 (valores maiores que 1 são arredondados para 1). Valores maiores que 0.90 indicam bom ajuste. O TLI utiliza a “chi-quadrado relativa” (\\(\\chi^2/df\\)), onde \\(\\chi^2/df = 1\\) indica ajuste perfeito, e valores acima de 2 ou 5 podem indicar ajuste inadequado.\nÍndices de Ajuste Absolutos: Avaliam o ajuste do modelo diretamente em relação aos dados observados, sem comparação com um modelo de linha de base.\nRMSEA (Root Mean Square Error of Approximation): Mede o erro de aproximação. Valores \\(\\le 0.05\\) indicam um ajuste próximo, entre \\(0.05\\) e \\(0.08\\) indicam um ajuste razoável, e \\(\\ge 0.10\\) indicam um ajuste ruim.\n\nÍndice de Modificação (MI): É um teste de qui-quadrado de 1 grau de liberdade que avalia o quanto o chi-quadrado do modelo mudaria se um parâmetro específico fosse incluído. MIs elevados sugerem um grande impacto na melhoria do ajuste.\n\nCuidado: A modificação do modelo com base exclusivamente no MI deve ser feita com justificativa teórica, para evitar a superestimação do ajuste e o aumento do Erro Tipo I (falsos positivos)."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#exemplos-de-aplicações",
    "href": "posts/Modelo de Equações Estruturais/index.html#exemplos-de-aplicações",
    "title": "Modelo de Equações Estruturais",
    "section": "Exemplos de Aplicações",
    "text": "Exemplos de Aplicações\nDois exemplos clássicos de aplicação são:\n\nModelo de Realização de Status Socioeconômico: Um modelo da teoria da estratificação social que investiga como a origem socioeconômica (variáveis como escolaridade dos pais e status socioeconômico da ocupação do pai) influencia o destino socioeconômico (medido por variáveis como escolaridade do próprio indivíduo, status socioeconômico da ocupação e rendimento do trabalho). Este modelo é relevante para entender a transmissão intergeracional da desigualdade, muitas vezes revelando que os efeitos indiretos são mais proeminentes que os diretos .\n\nModelo de Determinação do Índice de Gestão Descentralizada Municipal (IGD-M): Aplicado na área de políticas sociais, este modelo busca explicar os fatores que determinam a qualidade da gestão de programas sociais em nível municipal. Pode incluir variáveis como renda per capita, PIB per capita e a proporção de beneficiários de programas sociais, revelando a dependência municipal de recursos externos e a complexa relação entre desenvolvimento econômico e qualidade da gestão social."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#hands-on-aplicação-do-sem-em-software-estatístico",
    "href": "posts/Modelo de Equações Estruturais/index.html#hands-on-aplicação-do-sem-em-software-estatístico",
    "title": "Modelo de Equações Estruturais",
    "section": "Hands-on: Aplicação do SEM em Software Estatístico",
    "text": "Hands-on: Aplicação do SEM em Software Estatístico\nA aplicação prática do SEM é comumente realizada em softwares estatísticos. O pacote lavaan no R é amplamente utilizado por ser gratuito, de código aberto e relativamente fácil de usar. O STATA também emprega a aboradagem por meio do comando SEM.\nA sintaxe no lavaan é intuitiva:\n~: Usado para previsão (regressão), onde o resultado observado é previsto por preditores observados (e.g., y ~ x).\n=~: Usado para indicadores em modelos de mensuração, ligando uma variável latente aos seus indicadores observados (e.g., f =~ q + r + s).\n~~: Usado para covariância (e.g., x ~~ x para variância, x ~~ y para covariância).\n~1: Usado para estimar o intercepto ou média de uma variável (e.g., x ~ 1).\n\nlibrary(\"lavaan\")\nlibrary(\"lavaanPlot\")\n\ndata(\"PoliticalDemocracy\")\n\nm1 <- 'y1 ~ 1 + x1 + x2 + x3'\n\nfit1 <- sem(m1, data=PoliticalDemocracy)\n\nOs resultados obtidos são:\n\nsummary(fit1)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                            75\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  y1 ~                                                \n    x1                1.807    0.861    2.098    0.036\n    x2                0.017    0.477    0.036    0.971\n    x3               -0.307    0.382   -0.805    0.421\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .y1               -2.655    2.739   -0.970    0.332\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .y1                5.733    0.936    6.124    0.000\n\n\n\nlavaanPlot(model = fit1, \n           node_options = list(shape = \"box\", fontname = \"Helvetica\"), \n           edge_options = list(color = \"grey\"), \n           coefs = TRUE)"
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#análise-e-interpretação-dos-parâmetros-estimados",
    "href": "posts/Modelo de Equações Estruturais/index.html#análise-e-interpretação-dos-parâmetros-estimados",
    "title": "Modelo de Equações Estruturais",
    "section": "Análise e Interpretação dos Parâmetros Estimados",
    "text": "Análise e Interpretação dos Parâmetros Estimados\nA interpretação dos resultados de um modelo SEM envolve a análise de diferentes tipos de coeficientes e estatísticas:\n\nCoeficientes de Regressão (Caminhos Estruturais):\n\nCaminhos \\(\\Gamma\\) (Gamma): Representam a relação entre variáveis exógenas e variáveis endógenas (observadas ou latentes) [44, 105-107].\nCaminhos \\(B\\) (Beta): Representam a relação entre variáveis endógenas e outras variáveis endógenas (observadas ou latentes) [43, 44, 108, 109].\n\nCargas Fatoriais (Loadings, \\(\\Lambda\\)):\n\nIndicam a associação específica entre os fatores (variáveis latentes) e suas variáveis observadas (indicadores) [33, 35, 37, 110].\nEm termos padronizados (similar a correlações), cargas fatoriais próximas de 0.8 são consideradas boas, enquanto valores próximos de 0.4 podem ser questionáveis [62]. Cargas elevadas (e.g., > 0.70 ou 0.80) são geralmente desejáveis e indicam que as variáveis observadas convergem satisfatoriamente para formar o construto [111-113].\n\nVariâncias e Covariâncias:\n\nVariância de variáveis exógenas (\\(\\Phi\\)): A variância de uma variável exógena (observada ou latente) [105, 106].\nVariância Residual de variáveis endógenas (\\(\\Psi\\)): A variância não explicada da variável endógena após considerar a influência de seus preditores [105, 106, 114]. É o que “sobra” da previsão [115, 116].\nVariância Residual de Indicadores (\\(\\Theta\\)): No modelo de mensuração, é a variância não explicada dos indicadores após a influência do fator latente [39, 110].\nA presença de um “.” (ponto) antes do nome da variável na saída do lavaan geralmente indica uma variável endógena ou uma variância residual [114, 117].\n\nCoeficientes Padronizados: Facilitam a interpretação e a comparação da magnitude dos efeitos entre diferentes variáveis, pois transformam as variáveis para uma mesma escala (desvios padrão) [9, 71]."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#discussão-limitações-e-desafios-do-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#discussão-limitações-e-desafios-do-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "Discussão: Limitações e Desafios do SEM",
    "text": "Discussão: Limitações e Desafios do SEM\nApesar de suas muitas vantagens, a aplicação do SEM também apresenta desafios e limitações [88, 118]:\n\nRequisito de Teoria Forte: O SEM é uma abordagem confirmatória, o que significa que ele exige uma sólida base teórica para a especificação do modelo inicial [13, 15]. O sucesso de uma análise SEM depende da adequação da teoria subjacente; erros teóricos ou conceituais não podem ser corrigidos apenas por análises estatísticas [119].\nDesafio da Causalidade: Embora o SEM seja amplamente utilizado para análises causais [120, 121], estabelecer a causalidade definitiva requer a satisfação de três condições principais: associação estatística, precedência temporal e eliminação de causas concorrentes [122]. A última, em particular, é difícil de ser plenamente garantida com dados observacionais [123].\nSensibilidade ao Tamanho da Amostra: O teste chi-quadrado do modelo, um dos principais indicadores de ajuste, é muito sensível a amostras grandes, o que pode levar à sua rejeição mesmo para modelos bem ajustados na prática [68, 70-72]. Recomenda-se uma proporção de 20 observações para cada parâmetro estimado no modelo (\\(N:q\\) rule) [124].\nUso Criterioso dos Índices de Modificação: Embora os índices de modificação possam sugerir melhorias no modelo, seu uso excessivo ou sem justificativa teórica pode levar a modelos espúrios e aumentar o Erro Tipo I (falsos positivos), comprometendo a replicabilidade dos resultados [84-87].\nComplexidade de Interpretação (LISREL): A notação LISREL original pode ser complexa [12, 17]. No entanto, softwares modernos como lavaan simplificaram essa complexidade, tornando o SEM mais acessível [17, 103]."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#o-que-é-e-por-que-utilizar-o-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#o-que-é-e-por-que-utilizar-o-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "",
    "text": "Os Modelos de Equações Estruturais (SEM) são uma estrutura de modelo linear que permite modelar equações de regressão simultâneas com variáveis latentes [3, 4]. Eles englobam uma ampla gama de modelos, como regressão linear, regressão multivariada, análise de trajetória (path analysis), análise fatorial confirmatória (CFA) e regressão estrutural, todos considerados casos especiais do SEM [3-5]. Essencialmente, o SEM pode ser visto como uma combinação de análise fatorial e regressão [1]. O SEM implica uma estrutura para as covariâncias entre as variáveis observadas [1].\nA utilização do SEM oferece diversas vantagens [6]: * Permite trabalhar simultaneamente com estimação e mensuração: O SEM consegue integrar modelos de mensuração (como variáveis latentes são medidas) e modelos estruturais (as relações causais entre elas) [6, 7]. * Estimação de efeitos diretos e indiretos: O SEM possibilita a decomposição de efeitos estatísticos entre efeitos diretos e indiretos de variáveis explicativas sobre variáveis de resposta [6, 8, 9]. * Robustez: É uma técnica bastante robusta devido ao relaxamento de pressupostos, especialmente quando comparado à regressão de mínimos quadrados ordinários (MQO), pois não exige a satisfação do pressuposto de independência dos erros (em modelos não-recursivos) [6, 10]. * Facilidade interpretativa: A visualização através de diagramas de trajetória simplifica a interpretação dos modelos complexos [6, 11, 12]."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#contextualização-quando-usar-o-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#contextualização-quando-usar-o-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "Contextualização: Quando usar o SEM?",
    "text": "Contextualização: Quando usar o SEM?\nO SEM é, fundamentalmente, uma técnica de análise estatística confirmatória [13, 14]. Isso significa que ele não se presta à exploração de dados [13, 14]. Pelo contrário, o SEM exige que o pesquisador tenha uma sólida confiança teórica no modelo inicial a ser estimado [15]. É a ferramenta ideal quando o analista já possui um conhecimento aprofundado sobre a questão que está analisando, incluindo as relações esperadas entre variáveis observadas e construtos latentes, e a forma como esses construtos são medidos [16]."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#breve-histórico-do-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#breve-histórico-do-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "Breve histórico do SEM",
    "text": "Breve histórico do SEM\nOs fundamentos técnicos de todos os modelos SEM são baseados na notação clássica LISREL (linear structural relations) em homenagem a Karl Joreskög, que a inventou em 1969 e 1973. Embora o SEM seja considerado um campo relativamente novo na estatística, com base em 1976, todas as implementações modernas do SEM são derivações do LISREL, seja expandindo suas capacidades ou simplificando sua complexidade. A compreensão da notação LISREL é, portanto, fundamental para entender as estruturas mais recentes do SEM."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Sobre",
    "section": "Education",
    "text": "Education\nDoutorado em Desenvolvimento Econômico. Universidade Federal do Paraná, UFPR, Brasil | 2016 - 2020\nMestrado em Economia. Universidade de São Paulo, USP-RP, Brasil | 2013 - 2015\nGraduação em Ciências Econômicas. Universidade de São Paulo, USP, Brasil | 2009 - 2012"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Sobre",
    "section": "Experience",
    "text": "Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018"
  },
  {
    "objectID": "posts/MCRL/index.html",
    "href": "posts/MCRL/index.html",
    "title": "Modelo Clássico de Regressão MCRL",
    "section": "",
    "text": "Hipóteses do Modelo Clássico de Regressão Linear Múltipla (MCRLM)\nEquação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "posts/Diagnostico e previsao/index.html",
    "href": "posts/Diagnostico e previsao/index.html",
    "title": "Diagnóstico e previsão",
    "section": "",
    "text": "O ajuste do modelo, o valor previsto e os resíduos"
  },
  {
    "objectID": "posts/Endogeneidade e variaveis instrumentais/index.html",
    "href": "posts/Endogeneidade e variaveis instrumentais/index.html",
    "title": "Endogeneidade e Variáveis Instrumentais",
    "section": "",
    "text": "Endogeneidade e Variaveis Instrumentais\nEquação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "posts/Especificacao e interpretacao/index.html",
    "href": "posts/Especificacao e interpretacao/index.html",
    "title": "Especificação e Interpretação",
    "section": "",
    "text": "Especificação e Interpretação"
  },
  {
    "objectID": "posts/Heteroscedasticidade/index.html",
    "href": "posts/Heteroscedasticidade/index.html",
    "title": "Heteroscedasticidade",
    "section": "",
    "text": "Heteroscedasticidade\nEquação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "posts/Inferencia e testes de Hipoteses/index.html",
    "href": "posts/Inferencia e testes de Hipoteses/index.html",
    "title": "Inferência e teste de Hipótese",
    "section": "",
    "text": "Inferência e teste de Hipótese\nEquação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "posts/Propriedades grandes e pequenas amostras/index.html",
    "href": "posts/Propriedades grandes e pequenas amostras/index.html",
    "title": "Propriedades dos Estimadores",
    "section": "",
    "text": "Propriedades dos Estimadores: pequenas e grandes amostras"
  },
  {
    "objectID": "posts/Variaveis binarias/index.html",
    "href": "posts/Variaveis binarias/index.html",
    "title": "Variáveis Binárias",
    "section": "",
    "text": "Variáveis Binárias\nEquação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#o-que-é-o-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#o-que-é-o-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "O que é o SEM?",
    "text": "O que é o SEM?\nA Modelagem de Equações Estruturais (SEM) é uma técnica estatística multivariada extremamente poderosa usada para testar e estimar relações de causalidade entre múltiplas variáveis. Ela combina aspectos da análise fatorial (que lida com variáveis latentes, ou seja, conceitos não observáveis diretamente, como “satisfação” ou “inteligência”) e da análise de regressão múltipla (que analisa as relações de dependência entre variáveis).\nUm modelo SEM é geralmente representado por um diagrama que mostra as relações hipotéticas entre: Variáveis Latentes e Variáveis Observadas\n\nVariáveis Latentes: Conceitos abstratos que não podem ser medidos diretamente (ex: bem-estar, inteligência, burnout).\nVariáveis Observadas (ou Indicadores): Dados que podem ser medidos diretamente e que servem como indicadores das variáveis latentes (ex: respostas a perguntas de um questionário).\n\nO SEM pode ser visto como uma combinação de análise fatorial e regressão\nA análise fatorial pode ser dividida em dois tipos principais: exploratória e confirmatória.\n\nA análise fatorial exploratória, também conhecida como AFE, como o nome sugere, é uma ferramenta exploratória para entender as traços latentes (atributos psicológicos) subjacentes de uma escala desconhecida.\nA análise fatorial confirmatória toma emprestados muitos dos mesmos conceitos da análise fatorial exploratória, exceto que, em vez de deixar os dados nos dizerem a estrutura fatorial, nós pré-determinamos a estrutura fat orial e verificamos a estrutura latente de uma escala previamente desenvolvida.\n\nA análise fatorial confirmatória - ou confirmatory factor analysis (CFA) - participa frequentemente do abordagem guarda-chuva do SEM"
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#por-que-utilizar-o-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#por-que-utilizar-o-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "Por que utilizar o SEM?",
    "text": "Por que utilizar o SEM?\nVisão Holística do Modelo Use a SEM para testar um sistema completo de relações de uma só vez. Em vez de analisar cada hipótese separadamente (o que aumenta o risco de erro), a SEM avalia se o seu modelo teórico como um todo é compatível com os dados, oferecendo uma visão global e integrada do fenômeno.\nMedição Precisa de Conceitos Abstratos A SEM é ideal para medir conceitos abstratos (variáveis latentes) como “satisfação” ou “ansiedade”. Ela faz isso usando múltiplos indicadores (perguntas de um questionário) e, crucialmente, separa a medição do conceito do seu erro de medição. Isso resulta em estimativas muito mais puras e confiáveis das relações entre as variáveis."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#quando-usar-o-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#quando-usar-o-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "Quando usar o SEM?",
    "text": "Quando usar o SEM?\nA Modelagem de Equações Estruturais é uma ferramenta estatística confirmatória, não exploratória. Ela pode ser aplicada de três maneiras distintas:\n\nI. Confirmação Direta: Testar um único modelo teórico para validá-lo ou invalidá-lo.\n\nModelos Alternativos: Comparar modelos concorrentes para ver qual explica melhor os dados.\n\n\nDesenvolvimento do Modelo: Iniciar com um modelo teórico e, caso ele não se ajuste bem, modificá-lo em busca de uma versão melhor e mais simples (parcimoniosa)."
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#vantagem-do-sem",
    "href": "posts/Modelo de Equações Estruturais/index.html#vantagem-do-sem",
    "title": "Modelo de Equações Estruturais",
    "section": "Vantagem do SEM",
    "text": "Vantagem do SEM\nOs Modelos de Equações Estruturais englobam uma ampla gama de abordagens:\n\nRegressão linear e multivariada\nAnálise de trajetória (path analysis)\nAnálise fatorial confirmatória (CFA)\nRegressão estrutural\n\nEssa abordagem Guarda-chuva representa sua maior vantagem"
  },
  {
    "objectID": "posts/Modelo de Equações Estruturais/index.html#diagramas-de-caminho-ou-diagramas-de-trajetória",
    "href": "posts/Modelo de Equações Estruturais/index.html#diagramas-de-caminho-ou-diagramas-de-trajetória",
    "title": "Modelo de Equações Estruturais",
    "section": "Diagramas de Caminho ou Diagramas de Trajetória",
    "text": "Diagramas de Caminho ou Diagramas de Trajetória\nOs diagramas de trajetória são representações visuais essenciais dos modelos SEM, facilitando a compreensão das relações complexas que podem ser difíceis de visualizar apenas com equações matriciais.\n\n\n\nExemplo de diagrama de trajetória\n\n\nOs símbolos utilizados nos diagramas são padronizados: Círculos: Representam variáveis latentes (fatores ou construtos). Quadrados: Representam variáveis observadas (indicadores ou itens). Triângulos: Representam interceptos ou médias (geralmente não explicitados por padrão no lavaan a menos que solicitados). Setas únicas (de uma via): Indicam caminhos de regressão ou relações causais diretas (ex: uma variável predizendo outra). Setas duplas (de duas vias): Indicam variâncias (se a seta aponta para a própria variável, formando um loop) ou covariâncias (se a seta conecta duas variáveis) .\nExemplo de leitura de um diagrama: Uma seta de um círculo para um quadrado indica que uma variável latente (fator) prediz uma variável observada (indicador), o que é parte de um modelo de mensuração ou medida. Uma seta dupla em um círculo ou quadrado representa a variância daquela variável (latente ou observada). Uma seta dupla entre dois círculos ou dois quadrados indica a covariância entre essas duas variáveis."
  }
]